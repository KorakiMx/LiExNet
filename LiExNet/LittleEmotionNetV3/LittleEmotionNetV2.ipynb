{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef656b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e9e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 6)         168       \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 64, 64, 6)         24        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_3 (Depthw  (None, 64, 64, 6)         60        \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 64, 64, 6)         24        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 64, 64, 12)        84        \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 12)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 24)        312       \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 32, 32, 24)        96        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_4 (Depthw  (None, 32, 32, 24)        240       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 32, 32, 24)        96        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 32, 24)        600       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 24)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 16, 16, 48)        1200      \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 16, 16, 48)        192       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_5 (Depthw  (None, 16, 16, 48)        480       \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 16, 16, 48)        192       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 48)        2352      \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 48)                0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                1176      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 24)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 175       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7471 (29.18 KB)\n",
      "Trainable params: 7159 (27.96 KB)\n",
      "Non-trainable params: 312 (1.22 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "7/7 [==============================] - 0s 15ms/step- loss: 2.1986 - accuracy: 0.\n",
      "Epoch 1 — F1: 0.0782, Precision: 0.0476, Recall: 0.2183\n",
      "392/392 [==============================] - 6s 11ms/step - loss: 2.1986 - accuracy: 0.2054 - val_loss: 2.2019 - val_accuracy: 0.2183\n",
      "Epoch 2/400\n",
      " 19/392 [>.............................] - ETA: 3s - loss: 2.1261 - accuracy: 0.2632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\anaconda3\\envs\\hardware\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87/392 [=====>........................] - ETA: 2s - loss: 2.1368 - accuracy: 0.2701"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, regularizers, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configurar TensorFlow para usar solo la CPU\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Define el directorio de la base de datos CK+\n",
    "directorio = r'C:\\Users\\joshu\\OneDrive\\Desktop\\archive'\n",
    "\n",
    "\n",
    "# Define el mapeo de emociones a etiquetas numéricas basadas en las carpetas\n",
    "emociones = {\n",
    "    'anger': 0,\n",
    "    'contempt': 1,\n",
    "    'disgust': 2,\n",
    "    'fear': 3,\n",
    "    'happy': 4,\n",
    "    'sadness': 5,\n",
    "    'surprise': 6\n",
    "}\n",
    "\n",
    "# Crear listas para las imágenes y las etiquetas\n",
    "imagenes_data = []\n",
    "etiquetas = []\n",
    "\n",
    "# Recorrer las carpetas de emociones\n",
    "for emocion, etiqueta in emociones.items():\n",
    "    carpeta_emocion = os.path.join(directorio, emocion)\n",
    "    if not os.path.exists(carpeta_emocion):\n",
    "        continue\n",
    "    contenido = os.listdir(carpeta_emocion)\n",
    "\n",
    "    # Cargar imágenes y etiquetas\n",
    "    for nombre_imagen in contenido:\n",
    "        ruta_imagen = os.path.join(carpeta_emocion, nombre_imagen)\n",
    "        if nombre_imagen.endswith(('.png', '.jpg', '.jpeg', '.tiff')):\n",
    "            imagen_actual = cv2.imread(ruta_imagen, cv2.IMREAD_GRAYSCALE)\n",
    "            imagen_actual = cv2.resize(imagen_actual, (128, 128))  # Reducir tamaño\n",
    "            imagen_rgb = cv2.cvtColor(imagen_actual, cv2.COLOR_GRAY2RGB)\n",
    "            imagen_rgb = imagen_rgb / 255.0  # Normalizar\n",
    "            imagenes_data.append(imagen_rgb)\n",
    "            etiquetas.append(etiqueta)\n",
    "\n",
    "# Convertir listas a arreglos numpy\n",
    "imagenes_data = np.array(imagenes_data)\n",
    "etiquetas = np.array(etiquetas)\n",
    "\n",
    "# Separar los datos en conjuntos de entrenamiento y validación\n",
    "imagenes_train, imagenes_val, etiquetas_train, etiquetas_val = train_test_split(\n",
    "    imagenes_data, etiquetas, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Configurar aumento de datos\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Ajustar el generador al conjunto de entrenamiento\n",
    "datagen.fit(imagenes_train)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "\n",
    "# Definir la entrada\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Primera capa convolucional con Depthwise separable para mantener eficiencia, con menos filtros\n",
    "model.add(layers.Conv2D(6, (3, 3), strides=(2, 2), padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(12, (1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Segunda serie de capas convolucionales, con reducción de filtros\n",
    "model.add(layers.Conv2D(24, (1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(24, (1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Bloque final con menos filtros en las convoluciones\n",
    "model.add(layers.Conv2D(48, (1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(48, (1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "# Capas densas finales con Dropout ajustado y menor cantidad de unidades\n",
    "model.add(layers.Dense(24, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(layers.Dropout(0.3))  # Dropout ajustado para reducir sobreajuste\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Implementar EarlyStopping y reducción de learning rate en Plateau\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=10)\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir un callback personalizado para calcular F1, Precision, y Recall\n",
    "class MetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.f1s = []\n",
    "        self.precisions = []\n",
    "        self.recalls = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_predicciones = np.argmax(self.model.predict(self.validation_data[0]), axis=1)\n",
    "        val_etiquetas = self.validation_data[1]\n",
    "        \n",
    "        f1 = f1_score(val_etiquetas, val_predicciones, average='weighted')\n",
    "        precision = precision_score(val_etiquetas, val_predicciones, average='weighted')\n",
    "        recall = recall_score(val_etiquetas, val_predicciones, average='weighted')\n",
    "        \n",
    "        self.f1s.append(f1)\n",
    "        self.precisions.append(precision)\n",
    "        self.recalls.append(recall)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} — F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    # Sobrescribimos el método set_validation_data para obtener el conjunto de validación\n",
    "    def set_validation_data(self, validation_data):\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "# Instanciar el callback y pasar los datos de validación explícitamente\n",
    "metrics_callback = MetricsCallback()\n",
    "metrics_callback.set_validation_data((imagenes_val, etiquetas_val))\n",
    "# Configurar TensorFlow para usar solo la CPU\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "model.summary()\n",
    "\n",
    "# Entrenar el modelo con el callback\n",
    "history = model.fit(\n",
    "    imagenes_train, etiquetas_train,\n",
    "    validation_data=(imagenes_val, etiquetas_val),\n",
    "    epochs=400,\n",
    "    batch_size=2,\n",
    "    callbacks=[metrics_callback]\n",
    ")\n",
    "\n",
    "# Graficar F1, Precision y Recall a lo largo de las épocas\n",
    "epocas = range(1, len(metrics_callback.f1s) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epocas, metrics_callback.f1s, label='F1 Score')\n",
    "plt.plot(epocas, metrics_callback.precisions, label='Precision')\n",
    "plt.plot(epocas, metrics_callback.recalls, label='Recall')\n",
    "plt.title('F1, Precision y Recall a lo largo de las épocas')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Valor')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "# Función para calcular F1, Precision, y Recall\n",
    "def calcular_metricas(model, imagenes_val, etiquetas_val):\n",
    "    predicciones = model.predict(imagenes_val)\n",
    "    predicciones_clases = np.argmax(predicciones, axis=1)\n",
    "    \n",
    "    f1 = f1_score(etiquetas_val, predicciones_clases, average='weighted')\n",
    "    precision = precision_score(etiquetas_val, predicciones_clases, average='weighted')\n",
    "    recall = recall_score(etiquetas_val, predicciones_clases, average='weighted')\n",
    "    \n",
    "    return f1, precision, recall\n",
    "\n",
    "def calcular_flops(model):\n",
    "    # Crear una función concreta del modelo\n",
    "    imagen_de_prueba = tf.random.normal([1, 128, 128, 3])  # Imagen de prueba\n",
    "    modelo_funcional = tf.function(lambda x: model(x))\n",
    "    modelo_concreto = modelo_funcional.get_concrete_function(imagen_de_prueba)\n",
    "\n",
    "    # Convertir el modelo concreto a un gráfico de TensorFlow\n",
    "    frozen_func = convert_variables_to_constants_v2(modelo_concreto)\n",
    "    frozen_func.graph.as_graph_def()\n",
    "\n",
    "    # Utilizar tf.compat.v1.profiler para obtener el número de FLOPS\n",
    "    run_meta = tf.compat.v1.RunMetadata()\n",
    "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "    # Iniciar el profiler\n",
    "    flops = tf.compat.v1.profiler.profile(graph=frozen_func.graph, run_meta=run_meta, cmd='scope', options=opts)\n",
    "\n",
    "    # Devolver los FLOPS\n",
    "    return flops.total_float_ops  # Esta función devuelve el número total de operaciones de punto flotante\n",
    "\n",
    "\n",
    "# Función para calcular la huella de memoria\n",
    "def calcular_memoria_modelo(model):\n",
    "    # Contar los parámetros del modelo\n",
    "    total_params = model.count_params()\n",
    "    \n",
    "    # Asumiendo que los parámetros están almacenados en float32 (4 bytes por parámetro)\n",
    "    bytes_por_param = 4\n",
    "    memoria_total = total_params * bytes_por_param\n",
    "    \n",
    "    # Convertir a MB\n",
    "    memoria_total_mb = memoria_total / (1024 ** 2)\n",
    "    return memoria_total_mb\n",
    "\n",
    "# Obtener métricas en el conjunto de validación\n",
    "f1, precision, recall = calcular_metricas(model, imagenes_val, etiquetas_val)\n",
    "\n",
    "# Obtener los parámetros del modelo\n",
    "parametros = model.count_params()\n",
    "\n",
    "# Extraer Accuracy y Loss de la última época\n",
    "acc = history.history['accuracy'][-1]\n",
    "val_acc = history.history['val_accuracy'][-1]\n",
    "loss = history.history['loss'][-1]\n",
    "val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "# Calcular FLOPS y huella de memoria\n",
    "flops = calcular_flops(model)\n",
    "memoria_modelo = calcular_memoria_modelo(model)\n",
    "\n",
    "# Imprimir la tabla con los resultados\n",
    "print(f\"Acc: {acc}, F1: {f1}, P: {precision}, R: {recall}, Loss: {loss}, Parámetros: {parametros}, FLOPS: {flops}, Memoria: {memoria_modelo:.2f} MB\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Crear un diccionario con los resultados de la última época\n",
    "resultados = {\n",
    "    'Métrica': ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'Loss', 'Parámetros', 'FLOPS', 'Memoria (MB)'],\n",
    "    'Valor': [acc, f1, precision, recall, loss, parametros, flops, memoria_modelo]\n",
    "}\n",
    "\n",
    "# Convertir el diccionario en un DataFrame de pandas\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Guardar la tabla en un archivo Excel\n",
    "#ruta_excel = r\"C:\\Users\\joshu\\OneDrive\\Desktop\\MNJ2MPCK.xlsx\"\n",
    "#df_resultados.to_excel(ruta_excel, index=False)\n",
    "\n",
    "# Mostrar el archivo guardado\n",
    "#ruta_excel\n",
    "# Graficar las métricas\n",
    "epocas = range(len(history.history['accuracy']))\n",
    "\n",
    "# Graficar Accuracy\n",
    "plt.figure()\n",
    "plt.plot(epocas, history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(epocas, history.history['val_accuracy'], label='Validación')\n",
    "plt.title('Accuracy por Época')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Graficar Loss\n",
    "plt.figure()\n",
    "plt.plot(epocas, history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(epocas, history.history['val_loss'], label='Validación')\n",
    "plt.title('Loss por Época')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Graficar F1, Precision, Recall\n",
    "metricas = ['F1 Score', 'Precision', 'Recall']\n",
    "valores = [f1, precision, recall]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(metricas, valores)\n",
    "plt.title('F1, Precision y Recall en la última época')\n",
    "plt.ylabel('Valor')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Realizar predicciones con el modelo\n",
    "y_pred = model.predict(imagenes_val)\n",
    "y_pred_clases = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "acc_val = accuracy_score(etiquetas_val, y_pred_clases)\n",
    "\n",
    "# Matriz de confusión de validación\n",
    "matriz_confusion_val = confusion_matrix(etiquetas_val, y_pred_clases)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "ax = sn.heatmap(matriz_confusion_val, annot=True, cmap='Blues')\n",
    "ax.set_title('Validation data Confusion Matrix')\n",
    "ax.set_xlabel('Predicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "\n",
    "# Ajustar los labels de los ticks\n",
    "ax.xaxis.set_ticklabels(['NE', 'HA', 'SA', 'SU', 'AN', 'DI', 'FE'])\n",
    "ax.yaxis.set_ticklabels(['NE', 'HA', 'SA', 'SU', 'AN', 'DI', 'FE'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Informe de clasificación\n",
    "target_names = ['NE', 'HA', 'SA', 'SU', 'AN', 'DI', 'FE']\n",
    "report = classification_report(etiquetas_val, y_pred_clases, digits=4, target_names=target_names)\n",
    "print(report)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82950fcc",
   "metadata": {},
   "source": [
    "VISUALIZACIONES DE PESO Y DATOS ESTADISTICOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f72810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "# Modelo original\n",
    "model_input = model.input\n",
    "layer_outputs = [layer.output for layer in model.layers]  # Obtenemos las salidas de todas las capas\n",
    "activation_model = Model(inputs=model_input, outputs=layer_outputs)  # Modelo para activaciones\n",
    "\n",
    "# Escoge una imagen del conjunto de entrenamiento para visualizar\n",
    "img = imagenes_train[0]  # Puedes cambiar el índice para seleccionar otras imágenes\n",
    "img = img.reshape(1, 128, 128, 3)  # Cambia el tamaño según la entrada del modelo\n",
    "\n",
    "# Obtener las activaciones de todas las capas\n",
    "activations = activation_model.predict(img)\n",
    "\n",
    "# Visualizar activaciones para cada capa\n",
    "images_per_row = 8\n",
    "\n",
    "for layer_name, layer_activation in zip([layer.name for layer in model.layers], activations):\n",
    "    print(f\"Visualizando activaciones para la capa: {layer_name}\")\n",
    "    \n",
    "    if len(layer_activation.shape) == 4:  # Si la salida es 4D (batch_size, height, width, channels)\n",
    "        n_features = layer_activation.shape[-1]  # Número de filtros en la capa\n",
    "        size = layer_activation.shape[1]  # Tamaño espacial de los mapas de características\n",
    "\n",
    "        n_cols = n_features // images_per_row  # Número de columnas para organizar los gráficos\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
    "                channel_image -= channel_image.mean()  # Normalizar para mejorar la visualización\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                display_grid[col * size : (col + 1) * size,\n",
    "                             row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "        # Visualizar el grid de activaciones\n",
    "        scale = 1.0 / size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "        plt.show()\n",
    "    \n",
    "    elif len(layer_activation.shape) == 2:  # Si la salida es 2D (batch_size, features)\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.title(f\"Activaciones de la capa {layer_name}\")\n",
    "        plt.plot(layer_activation[0])\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(f\"No se puede visualizar la activación de la capa {layer_name} de dimensión {len(layer_activation.shape)}\")\n",
    "\n",
    "# Visualización de pesos para todas las capas\n",
    "for layer in model.layers:\n",
    "    try:\n",
    "        pesos, sesgos = layer.get_weights()\n",
    "\n",
    "        # Número de filtros en la capa\n",
    "        num_filtros = pesos.shape[-1]\n",
    "\n",
    "        # Tamaño del grid para visualizar los filtros\n",
    "        grid_size = int(np.ceil(np.sqrt(num_filtros)))\n",
    "\n",
    "        # Visualizar los filtros\n",
    "        fig, axes = plt.subplots(grid_size, grid_size, figsize=(10, 10))\n",
    "        for i in range(num_filtros):\n",
    "            filtro = pesos[:, :, 0, i]  # Extrayendo el filtro\n",
    "            ax = axes[i // grid_size, i % grid_size]\n",
    "            ax.imshow(filtro, cmap='viridis', aspect='auto')\n",
    "            ax.axis('off')\n",
    "        plt.suptitle(f'Pesos de la capa {layer.name}')\n",
    "        plt.show()\n",
    "    except:\n",
    "        # Algunas capas pueden no tener pesos, como MaxPooling2D\n",
    "        continue\n",
    "\n",
    "# Cálculo y visualización de estadísticas de pesos para todas las capas\n",
    "def calcular_entropia(pesos):\n",
    "    hist, _ = np.histogram(pesos, bins=256, density=True)\n",
    "    hist += 1e-7  # Evitar log(0)\n",
    "    return -np.sum(hist * np.log2(hist))\n",
    "\n",
    "for layer in model.layers:\n",
    "    try:\n",
    "        pesos, _ = layer.get_weights()\n",
    "\n",
    "        # Calcular estadísticas\n",
    "        media = np.mean(pesos)\n",
    "        varianza = np.var(pesos)\n",
    "        asimetria = skew(pesos.flatten())\n",
    "        curtosis_val = kurtosis(pesos.flatten())\n",
    "        entropia = calcular_entropia(pesos)\n",
    "        rango_val = np.ptp(pesos)\n",
    "\n",
    "        # Mostrar las estadísticas\n",
    "        print(f\"Capa: {layer.name}\")\n",
    "        print(f\"  Media: {media}\")\n",
    "        print(f\"  Varianza: {varianza}\")\n",
    "        print(f\"  Asimetría: {asimetria}\")\n",
    "        print(f\"  Curtosis: {curtosis_val}\")\n",
    "        print(f\"  Entropía: {entropia}\")\n",
    "        print(f\"  Rango: {rango_val}\")\n",
    "\n",
    "        # Graficar la evolución de las estadísticas\n",
    "        estadisticas = ['Media', 'Varianza', 'Asimetría', 'Curtosis', 'Entropía', 'Rango']\n",
    "        valores = [media, varianza, asimetria, curtosis_val, entropia, rango_val]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(estadisticas, valores, color='blue')\n",
    "        plt.title(f'Estadísticas de los Pesos de la Capa {layer.name}')\n",
    "        plt.ylabel('Valor')\n",
    "        plt.show()\n",
    "\n",
    "    except:\n",
    "        # Algunas capas pueden no tener pesos, como MaxPooling2D\n",
    "        continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a6b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600af43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hardware",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
